- func: cudnn_convolution_forward(Tensor input, Tensor weight, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) -> Tensor
  variants: function

- func: cudnn_convolution_transpose_backward(Tensor grad_output, Tensor weight, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) -> Tensor
  variants: function

- func: cudnn_convolution_full_forward(Tensor input, Tensor weight, Tensor bias, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) -> Tensor
  variants: function

- func: cudnn_convolution_transpose_full_forward(Tensor input, Tensor weight, Tensor bias, IntList padding, IntList output_padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) -> Tensor
  variants: function

- func: cudnn_convolution_backward(IntList input_size, Tensor grad_output, Tensor weight, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) -> Tensor
  variants: function

- func: cudnn_convolution_backward_weight(IntList weight_size, Tensor grad_output, Tensor input, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) -> Tensor
  variants: function

- func: cudnn_convolution_transpose_backward_weight(IntList weight_size, Tensor grad_output, Tensor input, IntList padding, IntList stride, IntList dilation, int64_t groups, bool benchmark, bool deterministic) -> Tensor
  variants: function

- func: cudnn_convolution_backward_bias(Tensor grad_output) -> Tensor
  variants: function

- func: cudnn_batch_norm_forward(Tensor input, Tensor weight, Tensor bias, Tensor running_mean, Tensor running_var, Tensor save_mean, Tensor save_var, bool training, double exponential_average_factor, double epsilon) -> Tensor
  variants: function

- func: cudnn_batch_norm_backward(Tensor input, Tensor grad_output, Tensor weight, Tensor save_mean, Tensor save_var, bool training, double epsilon) -> (Tensor, Tensor, Tensor)
  variants: function

# NB: input is special cased in a way I don't quite understand
- func: cudnn_grid_sampler(Tensor self, Tensor grid)
  return:
    - type: Tensor
      name: output
  variants: function
  dispatch: cudnn_grid_sampler_forward

- func: cudnn_grid_sampler_forward(Tensor self, Tensor grid)
  return:
    - type: Tensor
      name: output
  variants: function

- func: cudnn_grid_sampler_backward(Tensor self, Tensor grid, Tensor grad_output)
  return:
    - type: Tensor
      name: grad_self
    - type: Tensor
      name: grad_grid
  variants: function

- func: cudnn_affine_grid_generator(Tensor theta, int64_t N, int64_t C, int64_t H, int64_t W) -> Tensor
  return:
    - type: Tensor
      name: grid
  variants: function
  dispatch: cudnn_affine_grid_generator_forward

- func: cudnn_affine_grid_generator_forward(Tensor theta, int64_t N, int64_t C, int64_t H, int64_t W) -> Tensor
  return:
    - type: Tensor
      name: grid
  variants: function

# TODO: Why do I have to call this grad?!
- func: cudnn_affine_grid_generator_backward(Tensor grad, int64_t N, int64_t C, int64_t H, int64_t W)
  return:
    - type: Tensor
      name: grad_theta
  variants: function
